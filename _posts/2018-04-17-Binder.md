---

layout: post
title: "Binder篇"
date: 2018-04-17
categories: android

---

Tags : ZAZE android

[TOC]

* TOC
{:toc}

---

# Binder篇

## 参考资料

本文中的部分图片和解读说明摘自以下参考资料。

### 书籍

> **<< Android的设计和实现:卷I>>**
> **<<深入理解Android: 卷I>>**

### 链接

[Android系统开篇][Android系统开篇]
[为什么Android要采用Binder作为IPC机制][为什么Android要采用Binder作为IPC机制]
[Linux设备驱动之字符设备驱动][Linux设备驱动之字符设备驱动]
[Linux字符设备驱动框架][Linux字符设备驱动框架]
[Linux 的虚拟文件系统][Linux 的虚拟文件系统]
[设备与驱动的关系以及设备号、设备文件][设备与驱动的关系以及设备号、设备文件]

## 必须了解的一些概念

### 0.1 Linux

- Linux一切皆文件

![虚拟文件系统(VFS)][VFS]

```
    “一切皆是文件”是 Unix/Linux的基本哲学之一，所有的设备访问都是通过文件的方式，一般的数据文件、程序普通文件、目录、套接字，设备节点称为设备文件。
```

- 设备驱动和设备节点

```
    Linux的内核中大量使用"注册+回调"机制进行驱动程序的编写，简单的理解，就是当我们open一个设备文件的时候,其实是通过虚拟文件系统(VFS)找到相应的索引节点(inode)，并执行此前创建这个设备文件时注册在inode中的open函数，其他函数也是如此，所以，为了让我们写的驱动能够正常的被应用程序操作，首先要做的就是实现相应的方法，然后再创建相应的设备文件。
    Linux为所有的设备文件都提供了统一的操作函数接口，方法是使用数据结构struct file_operations。这个数据结构中包括许多操作函数的指针，如open()、close()、read()和write()等，但由于外设的种类较多，操作方式各不相同。
    Struct file_operations结构体中的成员为一系列的接口函数，如用于读/写的read/write函数和用于控制的ioctl等。打开一个文件就是调用这个文件file_operations中的open操作。不同类型的文件有不同的file_operations成员函数，如普通的磁盘数据文件，接口函数完成磁盘数据块读写操作；而对于各种设备文件，则最终调用各自驱动程序中的I/O函数进行具体设备的操作。这样，应用程序根本不必考虑操作的是设备还是普通文件，可一律当作文件处理，具有非常清晰统一的I/O接口。所以file_operations是文件层次的I/O接口。
```

```
    设备驱动程序(device driver)，简称驱动程序（driver），是一个允许高阶电脑软件与硬件交互的程序，这种程序创建了一个硬件与硬件或硬件与软件沟通的接口，经由主板上的总线(bus)或其它沟通子系统(subsystem)与硬件形成连接的机制，这样的机制使得硬件设备上的数据交换成为可能。
    字符设备(无缓冲)：只能一个字节一个字节的读写的设备，不能随机读取设备内存中的某一数据，读取数据需要按照先后顺序进行。字符设备是面向流的设备，常见的字符设备如鼠标、键盘、串口、控制台、LED等。
    块设备(有缓冲)：是指可以从设备的任意位置读取一定长度的数据设备。块设备如硬盘、磁盘、U盘和SD卡等存储设备。
    网络设备：网络设备比较特殊，不在是对文件进行操作，而是由专门的网络接口来实现。应用程序不能直接访问网络设备驱动程序。在/dev目录下也没有文件来表示网络设备。
    对于字符设备和块设备来说，在/dev目录下都有对应的设备文件。linux用户程序通过设备文件或叫做设备节点来使用驱动程序操作字符设备和块设备。
    
   字符设备是一种字节流设备，对设备的存取只能按顺序按字节的存取而不能随机访问，字符设备没有请求缓冲区，所有的访问请求都是按顺序执行的。字符设备可以通过文件系统节点来访问，这些设备文件和普通文件之间的唯一差别在于对普通文件的访问可以前后移动访问位置，而大多数字符设备是一个只能顺序访问的数据通道。
```

- 系统调用(system call : 系统呼叫)

```
    指运行在使用者空间的程序向操作系统内核请求需要更高权限运行的服务。
系统调用提供了用户程序与操作系统之间的接口。大多数系统交互式操作需求在内核态执行。如设备IO操作或者进程间通信。
    当设备打开（open）时，内核利用主设备号分派执行相应的驱动程序。次设备号只由相应的设备驱动程序使用。例如一个嵌入式系统，有两个LED指示灯，LED灯需要独立的打开或者关闭。那么，可以写一个LED灯的字符设备驱动程序，可以将其主设备号注册成5号设备，次设备号分别为1和2。这里，次设备号就分别表示两个LED灯。
```


### 0.2 IPC机制了解一下

```
- Socket(套接字) ： 主要用于不通机器或跨网络的通信，传输效率低
- Signal(信号) ： 适用于进程中断控制，比如非法内存访问，杀死某个进程等
- Pipe(管道) ： 在创建时分配一个page大小的内存，缓存区大小比较有限
- Message Queue ： 信息复制两次，额外的CPU消耗；不合适频繁或信息量大的通信
- Semaphore(信号量) : 常作为一种锁机制，防止某进程正在访问共享资源时，其他进程也访问该资源。因此，主要作为进程间以及同一进程内不同线程之间的同步手段
- Shared Memory(共享内存) : 无须复制，共享缓冲区直接付附加到进程虚拟地址空间，速度快；但进程间的同步问题操作系统无法实现，必须各进程利用同步工具解决；
....等等
```

### 0.3 Binder与C/S体系结构体会一下

```
- 用户端(Client) : 是C/S体系结构中使用Server端提供的Service的一方
- 服务端(Server) : 是C/S体系结构中为Client端提供Service的一方
- 服务代理(Proxy): 位于Client端, 提供访问服务的接口。主要作用是屏蔽用户端和Server端通讯的细节, 如对请求数据的序列化和对响应数据的反序列化、通信协议的处理等。
- 服务(Service): 运行在Server端，提供具体的功能处理Client端的请求。
- 服务存根(Stub): 位于Server端, 屏蔽了Proxy和Service端通信的细节，对Client端Proxy请求数据的反序列化和对Server端响应数据的序列化、通信协议的封装和处理、匹配Client端调用Service的具体方法，可以看作是Service的代理
- 通信协议：Client端和Server端可以运行于不同的进程中，甚至可以在不同的主机中，因此需要提供远程通信功能。在Android中，主要使用Binder作为Client端与Server端通信的协议。
```

## 一、 初窥Binder

### 1.1 什么是Binder

```
    Android是使用Linux的进程管理机制，以进程为单位分配虚拟地址空间。为了安全考虑，一个进程禁止直接与其他进程交互,也就是不同进程之间是相互隔离的(Process Isolation)。这时候如果需要进行通信，就必须通过Linux内核提供的进程间通讯(Inter Process Communication, IPC),具体的通信方式看下方。但是这些IPC方式要么效率低下，要么不适合封装给上层使用, 所以在Android 中并没有大规模使用，取而代之的使用Binder。
```
```
- Binder是Android对Linux内核层的一个扩展，属于字符设备驱动。主要操作有驱动设备的初始化(binder_init)，打开 (binder_open)，映射(binder_mmap)，数据操作(binder_ioctl)。
- Binder框架分成Native层和Java层。
- Android通过对Binder的封装，提供了一套Binder操作的框架，便于上层使用。
```


### 1.2 ServiceManager

![image_1cbjv1brnoa21sc21coacpb1rtrm.png-187.2kB][C/S和ServiceManager]

```
    在Android的C/S体系结构中增加了一个额外的组件ServiceManager, 提供了Service注册和Service检索功能。Service在启动过程中将自身信息注册到ServiceManager中,因此ServiceManager中维护了一个Service信息的列表。当Client要使用服务时，只需向ServiceManager提供所需Service的名字便可获取Service信息。ServiceManager是由init启动的进程，本身也是一个Server。
    ServiceManager是在init.rc中配置的Daemon System Service, 由boot Action 启动。ServiceManager优先于其他服务启动，在其启动后， 便可以对外提供服务注册、服务检索的功能。除此之外，它还维护了一个Binder通讯的上下文管理者(context manager)。
     ServiceManger是在系统启动阶段由init启动的service,对应可执行程序名为/system/bin/servicemanager。其程序入口为service_manager.c。
```

```
service servicemanager /system/bin/servicemanager
    class core 		# 类型为core，将由boot Action启动
    user system 	# 属于system用户
    group system	# 属于system组
    critical		# critical服务, 异常退出后盖服务需要重启
    # servicemanager 重启会导致以下服务重启
    onrestart restart healthd 	
    onrestart restart zygote
    onrestart restart media
    onrestart restart surfaceflinger
    onrestart restart drm
```
- main

```c

void *svcmgr_handle;
/**
 * 1. 初始化Binder通信环境，打开Binder设备并映射共享内存
 * 2. 将自身注册为上下文管理者
 * 3. 进入无限循环等待接收并处理IPC通信请求
 **/
int main(int argc, char **argv)
{
    struct binder_state *bs;
    // #define BINDER_SERVICE_MANAGER ((void*) 0)
    void *svcmgr = BINDER_SERVICE_MANAGER;
    // 打开Binder设备, 映射共享内存用于接收IPC通信数据, 申请的内存为128k
    bs = binder_open(128*1024);
    // 将service_manager注册为context manager
    if (binder_become_context_manager(bs)) {
        return -1;
    }
    svcmgr_handle = svcmgr;
    // 进入无限循环等待接受IPC通信数据
    binder_loop(bs, svcmgr_handler);
    return 0;
}
```

#### 1.2.1 Binder的初始化(binder_open)

```
由于进程的地址空间是彼此的隔离的，但是内核空间是可以共享的，因此要实现进程间通信，可以在内核中开辟缓冲区保存进程间通信数据，以此来实现共享内存。
- ServiceManager调用binder_open函数初始化Binder通信环境。(frameworks/base/cmds/service_manager/binder.c)
- binder_open 需要借助binder_state结构体来保存open和mmap系统调用的返回信息
```

```
1. open系统调用打开Binder设备文件, 以便访问Binder驱动程序。导致Binder驱动的binder_open函数被调用。(kernel/drivers/staging/android/binder.c)
2. mmap系统调用将Binder设备文件映射到进程的虚拟地址空间, 并通知Binder驱动程序在内核空间创建128KB的缓冲区来保存IPC数据。从而进程空间的某个内存区域和内核空间的某个内存区域建立了映射关系，当前进程的servicemanager可以利用内核缓冲区共享数据。
```

```c
struct binder_state
{
    int fd;         // open系统调用返回的文件描述符
    void *mapped;   // mmap系统调用 返回的映射区的起始地址
    unsigned mapsize;   // 映射区大小
};

/**
 * 1. 创建binder_state类型结构体 bs，并分配内存
 * 2. 通过open系统调用以读写方式方式打开设备文件
 * 3. 通过mmap系统调用将设备文件映射到当前进程的虚拟地址空间
 **/
struct binder_state *binder_open(unsigned mapsize)
{
    // 创建binder_state类型结构体 bs，并分配内存
    struct binder_state *bs;
    bs = malloc(sizeof(*bs));
    if (!bs) {
        errno = ENOMEM;
        return 0;
    }
    // 通过open系统调用以读写方式方式打开设备文件
    bs->fd = open("/dev/binder", O_RDWR);
    if (bs->fd < 0) {
        goto fail_open;
    }
    // 通过mmap系统调用将设备文件映射到当前进程的虚拟地址空间
    bs->mapsize = mapsize; // 128KB
    bs->mapped = mmap(NULL, mapsize, PROT_READ, MAP_PRIVATE, bs->fd, 0);
    if (bs->mapped == MAP_FAILED) {
        fprintf(stderr,"binder: cannot map device (%s)\n",
                strerror(errno));
        goto fail_map;
    }
    return bs;
// 处理错误代码
fail_map:
    // 关闭设备
    close(bs->fd);
fail_open:
    // 回收资源
    free(bs);
    return 0;
}
```

#### 1.2.2 注册上下文管理者(binder_become_context_manager)

```
    打开Binder设备并映射内存后， servicemanage会将自身注册为Binder通信的上下文管理者。
    一个字符设备驱动通常会实现常规的open、close、read、write等功能，但在一些细分的情境下，如果需要扩展新的功能，通常以增设ioctl()命令的方式实现，其作用类似于“拾遗补漏”。
```

- service_manager.c -> binder_become_context_manager
```c
int binder_become_context_manager(struct binder_state *bs)
{   
    // 调用Linux系统函数ioctl, 向Binder设备发送BINDER_SET_CONTEXT_MGR
    return ioctl(bs->fd, BINDER_SET_CONTEXT_MGR, 0);
}
```

#### 1.2.3 等待接收并处理IPC通信请求(binder_loop)

```
servicemanger是一个处理client请求的Server进程。
在其成为context manager之后便可以想要Service组件注册服务的请求和Client组件使用服务的请求。
当Service组件向serviceManager注册服务时，Service组件所在的进程对应servicemanger就是Client。
```

- binder_loop

```c
/**
 * 在进入无限循环前调用了binder_write函数。
 * 传入的参数有 binder_state类型的结构体，readbuf中存储了BC_ENTER_LOOPER指令。
 **/
void binder_loop(struct binder_state *bs, binder_handler func)
{
    int res;
    // 定义binder_write_read结构体，发送BINDER_WRITE_READ指令时使用
    struct binder_write_read bwr;
    unsigned readbuf[32];
    // write_size赋值为0，Binder驱动中需要判断这个变量
    bwr.write_size = 0;
    bwr.write_consumed = 0;
    bwr.write_buffer = 0;
    // BC_ENTER_LOOPER是Binder协议中的Binder Command指令,BC_为前缀
    readbuf[0] = BC_ENTER_LOOPER;
    // 标记当前线程进入Binder Looper状态， 看下面
    binder_write(bs, readbuf, sizeof(unsigned));
    // 进入循环
    for (;;) {
        bwr.read_size = sizeof(readbuf);
        bwr.read_consumed = 0;
        bwr.read_buffer = (unsigned) readbuf;
        // 本次ioctl调用将会进入BINDER_WRITE_READ分支
        // 由于write_size = 0, read_size > 0 将会调用binder_thread_read
        // 该函数用于从Binder驱动中读取IPC请求数据，从驱动层返回出来
        res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);
        if (res < 0) {
            // 异常
            break;
        }
        // 处理Binder请求, 看下面
        res = binder_parse(bs, 0, readbuf, bwr.read_consumed, func);
        if (res == 0) {
            LOGE("binder_loop: unexpected reply?!\n");
            break;
        }
        if (res < 0) {
            LOGE("binder_loop: io error %d %s\n", res, strerror(errno));
            break;
        }
    }
}
```

- binder_write

```
/**
 * binder_ioctl函数被调用，进入BINDER_WRITE_READ分支
 * 本次调用将会根据进程在用户空间设置bwr.write_size值，进入binder_thread_write函数
 * binder_thead_write调用进入BC_ENTER_LOOPER处理分支，标记当前线程进入Binder Looper状态。
 */
int binder_write(struct binder_state *bs, void *data, unsigned len)
{
    struct binder_write_read bwr;
    int res;
    bwr.write_size = len;
    bwr.write_consumed = 0;
    bwr.write_buffer = (unsigned) data;
    bwr.read_size = 0;
    bwr.read_consumed = 0;
    bwr.read_buffer = 0;
    // 传入指令BINDER_WRITE_READ
    res = ioctl(bs->fd, BINDER_WRITE_READ, &bwr);
    if (res < 0) {
        fprintf(stderr,"binder_write: ioctl failed (%s)\n",
                strerror(errno));
    }
    return res;
}
```

- binder_parse

```
/**
 * 在上次ioctl调用读取到IPC后，对返回数据进行解析
 * Binder驱动层可以返回多种BR指令给servicemanger， 其中BR_TRANSACTION指令用于注册和检索service。
 * func参数由svcmgr_handler指定, Binder驱动层的BR_TRANSACTION指令由它处理。
 **/
int binder_parse(struct binder_state *bs, struct binder_io *bio,
                 uint32_t *ptr, uint32_t size, binder_handler func)
{
    int r = 1;
    uint32_t *end = ptr + (size / 4);
    while (ptr < end) {
        uint32_t cmd = *ptr++; // 读取BR指令
        switch(cmd) {
        case BR_NOOP:
            break;
        case BR_TRANSACTION_COMPLETE:
            break;
        case BR_INCREFS:
        case BR_ACQUIRE:
        case BR_RELEASE:
        case BR_DECREFS:
            ptr += 2;
            break;
        case BR_TRANSACTION: {
            struct binder_txn *txn = (void *) ptr;
            if ((end - ptr) * sizeof(uint32_t) < sizeof(struct binder_txn)) {
                LOGE("parse: txn too small!\n");
                return -1;
            }
            binder_dump_txn(txn);
            if (func) {
                unsigned rdata[256/4];
                // Binder驱动发送给当前进程的IPC数据
                struct binder_io msg; 
                // 要写入Binder驱动的IPC数据
                struct binder_io reply;
                int res;
                // init
                bio_init(&reply, rdata, sizeof(rdata), 4);
                bio_init_from_txn(&msg, txn);
                // 调用func处理BR_TRANSACTION，处理结果保存在reply中
                res = func(bs, txn, &msg, &reply);
                // 处理结果返回给Binder程序
                binder_send_reply(bs, &reply, txn->data, res);
            }
            ptr += sizeof(*txn) / sizeof(uint32_t);
            break;
        }
        case BR_REPLY: {
            struct binder_txn *txn = (void*) ptr;
            if ((end - ptr) * sizeof(uint32_t) < sizeof(struct binder_txn)) {
                LOGE("parse: reply too small!\n");
                return -1;
            }
            binder_dump_txn(txn);
            if (bio) {
                bio_init_from_txn(bio, txn);
                bio = 0;
            } else {
                    /* todo FREE BUFFER */
            }
            ptr += (sizeof(*txn) / sizeof(uint32_t));
            r = 0;
            break;
        }
        case BR_DEAD_BINDER: {
            struct binder_death *death = (void*) *ptr++;
            death->func(bs, death->ptr);
            break;
        }
        case BR_FAILED_REPLY:
            r = -1;
            break;
        case BR_DEAD_REPLY:
            r = -1;
            break;
        default:
            LOGE("parse: OOPS %d\n", cmd);
            return -1;
        }
    }
    return r;
}
```

- svcmgr_handler

```
/**
 * servicemanager在接收到Binder驱动层的BR_TRANSACTION指令后, 操作有: 
 * 1. do_find_service : Client端的getService
 * 2. do_add_service : Client段的addService
 **/
int svcmgr_handler(struct binder_state *bs,
                   struct binder_txn *txn,
                   struct binder_io *msg,
                   struct binder_io *reply)
{
    struct svcinfo *si;
    uint16_t *s;
    unsigned len;
    void *ptr;
    uint32_t strict_policy;
    // 检查Binder驱动层传递的txn->targer
    if (txn->target != svcmgr_handle)
        return -1;
    // 读取并校验传递过来的IPC函数
    strict_policy = bio_get_uint32(msg);
    s = bio_get_string16(msg, &len);
    if ((len != (sizeof(svcmgr_id) / 2)) ||
        memcmp(svcmgr_id, s, sizeof(svcmgr_id))) {
        fprintf(stderr,"invalid id %s\n", str8(s));
        return -1;
    }
    // Binder驱动在接收到添加或者检索的Service的请求后，会在txn->code中记录相应的请求 
    switch(txn->code) {
    case SVC_MGR_GET_SERVICE:
    case SVC_MGR_CHECK_SERVICE:
        s = bio_get_string16(msg, &len);
        ptr = do_find_service(bs, s, len);
        if (!ptr)
            break;
        bio_put_ref(reply, ptr);
        return 0;

    case SVC_MGR_ADD_SERVICE:
        s = bio_get_string16(msg, &len);
        ptr = bio_get_ref(msg);
        if (do_add_service(bs, s, len, ptr, txn->sender_euid))
            return -1;
        break;

    case SVC_MGR_LIST_SERVICES: {
        unsigned n = bio_get_uint32(msg);

        si = svclist;
        while ((n-- > 0) && si)
            si = si->next;
        if (si) {
            bio_put_string16(reply, si->name);
            return 0;
        }
        return -1;
    }
    default:
        LOGE("unknown code %d\n", txn->code);
        return -1;
    }

    bio_put_uint32(reply, 0);
    return 0;
}
```



## 二、乱挖Binder驱动层


kernel/drivers/staging/android/binder.c

- binder_open

```c
/**
 * 驱动层的binder_open函数的作用是创建并初始化了binder_proc结构体, 
 * 该结构体记录了打开Binder设备的进程所对应的Binder通信信息。
 * 类似open系统调用, mmap系统调用导致驱动层的binder_mmap函数被调用。
 **/
static int binder_open(struct inode *nodp, struct file *filp)
{
    // 创建binder_proc结构体, binder进程
    struct binder_proc *proc; 
    // 为binder_proc结构体分配kernel内存空间
    proc = kzalloc(sizeof(*proc), GFP_KERNEL); 
    if (proc == NULL)
        return -ENOMEM;
    // 保存打开Binder设备的进程信息， 即servicemanager
    get_task_struct(current);
    // 将当前线程的task保存到binder进程的tsk
    proc->tsk = current;   
    // 初始化可执行列表
    INIT_LIST_HEAD(&proc->todo);
    // 初始化wait队列, 用于切换current进程到wait状态
    init_waitqueue_head(&proc->wait); 
    // 记录进程默认优先级(当前进程的nice值)
    proc->default_priority = task_nice(current); 
    // 同步锁，因为binder支持多线程访问
    binder_lock(__func__);   
    / /BINDER_PROC对象创建数加1
    binder_stats_created(BINDER_STAT_PROC);
    // 将proc_node节点添加到全局列表binder_procs中
    hlist_add_head(&proc->proc_node, &binder_procs); 
    proc->pid = current->group_leader->pid;
    //初始化已分发的死亡通知列表
    INIT_LIST_HEAD(&proc->delivered_death); 
    // 将proc存入filp结构体的private_data变量中
    filp->private_data = proc;       
    binder_unlock(__func__);
    return 0;
}
```

- binder_ioctl

|ioctl指令|说明|
|:-- |: --|
|BINDER_SET_CONTEXT_MSG|专门用于设置context manager,增加一个全局的Binder node节点，索引值为0 ，存入binder_context_mgr_node中，保证系统唯一。|
|BINDER_WRITE_READ|收发Binder IPC数据|

```
没代码

```


------
苦工 : [口戛口崩月危.Z][author]

[author]: https://zaze359.github.io
[为什么Android要采用Binder作为IPC机制]:https://www.zhihu.com/question/39440766/answer/89210950
[C/S和ServiceManager]: http://static.zybuluo.com/zaze/hd4k8fd8y0ky6lljv86bwkd9/image_1cbjv1brnoa21sc21coacpb1rtrm.png
[Linux设备驱动之字符设备驱动]: https://blog.csdn.net/andylauren/article/details/51803331
[Linux字符设备驱动框架]: https://www.cnblogs.com/xiaojiang1025/p/6181833.html
[Android系统开篇]: http://gityuan.com/android/
[Linux 的虚拟文件系统]: https://blog.csdn.net/heikefangxian23/article/details/51579971
[VFS]: http://www.ibm.com/developerworks/cn/linux/l-cn-vfs/3.jpg
[设备与驱动的关系以及设备号、设备文件]: https://www.cnblogs.com/lidabo/p/5300529.html